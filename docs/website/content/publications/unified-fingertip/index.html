<div class="modal fade" id="modal-unified" tabindex="-1" role="dialog" aria-labelledby="modal-unifiedTitle"
aria-hidden="true">
<div class="modal-dialog modal-xl" role="document">
    <div class="modal-content">
        <div class="modal-header paper-title-modal">
            <!-- paper title -->
            <h3 class="modal-title">
                A Unified Learning Approach for Hand Gesture Recognition and Fingertip Detection
            </h3>
            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
                <span aria-hidden="true">&times;</span>
            </button>
        </div>
        <div class="modal-body author-modal">
            <!-- authors -->
            <h6 class="card-subtitle">
                Mohammad Mahmudul Alam,
                Mohammad Tariqul Islam,
                S. M. Mahbubur Rahman
            </h6>
            <!-- journal/conf name -->
            <p class="card-text journal-conf-name">
                In Pattern Recognition, Elsevier, Science Publishers [In Progress]
            </p>
            <!-- buttons -->
            <div class="pubs-buttons">
                <a href="https://github.com/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection"
                    target="_blank">
                    <button type="button" class="btn btn-outline-primary btn-sm">GitHub</button>
                </a>
                <a href="https://github.com/MahmudulAlam/Unified-Gesture-and-Fingertip-Detection/tree/master/dataset"
                    target="_blank">
                    <button type="button" class="btn btn-outline-primary btn-sm">Dataset</button>
                </a>
                <a href="" target="_blank">
                    <button type="button" class="btn btn-outline-primary btn-sm d-none">Pre-print</button>
                </a>
                <a href="" target="_blank">
                    <button type="button" class="btn btn-outline-primary btn-sm d-none">PDF</button>
                </a>
            </div>
            <div class="abstract">
                <h3>Abstract</h3>
                <p>
                    In human-computer interaction or in sign language interpretation, recognizing hand gestures and detecting fingertips become ubiquitous in computer vision research. In this paper, a unified convolutional neural network (CNN) approach for both hand gesture recognition and fingertip detection are introduced. The proposed algorithm uses a single network to predict finger class probabilities and fingertips positional output in one evaluation. Instead of directly regressing fingertips position from the fully connected layer of the CNN, we regress ensemble of fingertips position from the fully convolutional network (FCN) and subsequently take ensemble average to regress the final fingertips positional output. Since the whole recognition and detection pipeline use a single network, it is extremely fast, runs at 76 frames per second. Compared to state-of-the-art methods, the proposed method makes less localization error and less likely to predict false positive and false negative. It outperforms other fingertip detection approach including Heatmap-based and End2End frameworks.
                </p>
                <div class="pubs-imgs">
                    <img src="content/publications/unified-fingertip/featured.jpg">
                </div>
            </div>
        </div>
        <div class="modal-footer">
            <button type="button" class="btn btn-secondary btn-lg btn-block" data-dismiss="modal">Close</button>
        </div>
    </div>
</div>
</div>